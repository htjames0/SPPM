{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8facda1",
   "metadata": {},
   "source": [
    "# Title Simple Stock Price Prediction Model\n",
    "Here I will be implementing a simple MLP neural network for stock price prediction.  My GitHub profile is htjames0 and all code and files can be found in the repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee21751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8cacf1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date       Open       High        Low      Close  Adj Close  \\\n",
      "0     2016-01-04   2.770000   2.820000   2.630000   2.770000   2.770000   \n",
      "1     2016-01-05   2.770000   2.800000   2.640000   2.750000   2.750000   \n",
      "2     2016-01-06   2.660000   2.710000   2.470000   2.510000   2.510000   \n",
      "3     2016-01-07   2.430000   2.480000   2.260000   2.280000   2.280000   \n",
      "4     2016-01-08   2.360000   2.420000   2.100000   2.140000   2.140000   \n",
      "...          ...        ...        ...        ...        ...        ...   \n",
      "1254  2020-12-24  91.800003  92.510002  91.309998  91.809998  91.809998   \n",
      "1255  2020-12-28  92.930000  93.139999  90.820000  91.599998  91.599998   \n",
      "1256  2020-12-29  91.660004  92.459999  89.430000  90.620003  90.620003   \n",
      "1257  2020-12-30  90.779999  92.849998  90.190002  92.290001  92.290001   \n",
      "1258  2020-12-31  92.099998  92.300003  90.870003  91.709999  91.709999   \n",
      "\n",
      "        Volume  \n",
      "0     32516800  \n",
      "1     12972300  \n",
      "2     23759400  \n",
      "3     22203500  \n",
      "4     31822400  \n",
      "...        ...  \n",
      "1254  16705900  \n",
      "1255  30627300  \n",
      "1256  31748200  \n",
      "1257  25845000  \n",
      "1258  24930700  \n",
      "\n",
      "[1259 rows x 7 columns]\n",
      "            Date        Open        High         Low       Close   Adj Close  \\\n",
      "1259  2021-01-04   92.110001   96.059998   90.919998   92.300003   92.300003   \n",
      "1260  2021-01-05   92.099998   93.209999   91.410004   92.769997   92.769997   \n",
      "1261  2021-01-06   91.620003   92.279999   89.459999   90.330002   90.330002   \n",
      "1262  2021-01-07   91.330002   95.510002   91.199997   95.160004   95.160004   \n",
      "1263  2021-01-08   95.980003   96.400002   93.269997   94.580002   94.580002   \n",
      "...          ...         ...         ...         ...         ...         ...   \n",
      "1399  2021-07-26   92.010002   92.750000   91.120003   91.820000   91.820000   \n",
      "1400  2021-07-27   92.940002   94.099998   89.099998   91.029999   91.029999   \n",
      "1401  2021-07-28   93.440002   98.709999   89.650002   97.930000   97.930000   \n",
      "1402  2021-07-29   96.580002  105.739998   96.580002  102.949997  102.949997   \n",
      "1403  2021-07-30  101.599998  106.970001  101.379997  106.190002  106.190002   \n",
      "\n",
      "         Volume  \n",
      "1259   51802600  \n",
      "1260   34208000  \n",
      "1261   51911700  \n",
      "1262   42897200  \n",
      "1263   39816400  \n",
      "...         ...  \n",
      "1399   27668500  \n",
      "1400   69427000  \n",
      "1401  140561000  \n",
      "1402  164091800  \n",
      "1403  125567000  \n",
      "\n",
      "[145 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('AMD.csv')\n",
    "#features will be Open, High, Low, and Volume\n",
    "#label will be Close\n",
    "\n",
    "#dividing the data set into train and test data\n",
    "train_end = data[data.Date=='2021-01-04'].index[0]\n",
    "train_data = data.iloc[:train_end,:]\n",
    "test_data = data.iloc[train_end:,:]\n",
    "\n",
    "#need to divide training data to account for the prediction days\n",
    "#i.e. how many days to look back in order to predict the next day\n",
    "#I plan to expirement with several windows - 15, 30, 45, 90 but \n",
    "#starting out with 90\n",
    "days = 90\n",
    "\n",
    "#partitioning data so to add a correct label for the number of features\n",
    "for i in range(days, len(tran_data)):\n",
    "    #features\n",
    "    x_train\n",
    "    #label\n",
    "    y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cbc6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPmodel(features, step_size, hidden_neurons=5, act='relu', loss_fxn='mean_squared_error'):\n",
    "    \n",
    "    #method inputs\n",
    "        #features - feature data used to get the number of input layer nodes\n",
    "        #step-size - for optimizer\n",
    "        #hidden_neurons - number of neurons in hidden layer, default of five\n",
    "        #act - activation function, default ReLu function\n",
    "        #loss_fxn - loss function, default as mean squared error\n",
    "    \n",
    "    #defining model\n",
    "    model = tf.keras.models.Sequential()\n",
    "   \n",
    "    #layers\n",
    "    model.add(tf.keras.layers.Dense(units=hidden_neurons,\n",
    "                                    input_shape=len(features.columns),\n",
    "                                    activation='relu')\n",
    "                                   )\n",
    "    model.add(tf.keras.layers.Dense(units = 1,\n",
    "                                    activation=act)\n",
    "                                   )\n",
    "    \n",
    "    #optimizer\n",
    "    opt = tf.keras.optimizers.Adam(learn_rate=step_size)\n",
    "    \n",
    "    #compile - loss fxn MSE\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=loss_fxn,\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "   \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bc9a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def train_model(model, feature, label, epochs, batch_size):\n",
    "\n",
    "    #feeding features and labels to model, model iterates epoch number of times\n",
    "    #using batch_size number of data points per iteration\n",
    "    history = model.fit(x=feature,\n",
    "                        y=label,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs)\n",
    "\n",
    "    #weights and bias\n",
    "    trained_weight = model.get_weights()[0]\n",
    "    trained_bias = model.get_bias()[1]\n",
    "\n",
    "    #historical data of model for each epoch\n",
    "    epochs = history.epoch\n",
    "    hist = pd.DateFram(history.history)\n",
    "\n",
    "    #rmse for each epoch\n",
    "    rmse = hist[\"root_mean_squared_error\"]\n",
    "\n",
    "    return trained_weight, trained_bias, epochs, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "013ddb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00daa6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
