{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8facda1",
   "metadata": {},
   "source": [
    "# Simple Stock Price Prediction Model\n",
    "Here I will be implementing a simple MLP neural network for stock price prediction.  My GitHub profile is htjames0 and all code and files can be found in the repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee21751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe6ce4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('AMD.csv')\n",
    "#features will be Open, High, Low, and Volume\n",
    "#label will be Close\n",
    "\n",
    "#dividing the data set into train and test data\n",
    "train_end = data[data.Date=='2021-01-04'].index[0]\n",
    "train_data = data.iloc[:train_end,:]\n",
    "test_data = data.iloc[train_end:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66348d",
   "metadata": {},
   "source": [
    "# Data Methods\n",
    "\n",
    "Training Data Method: \n",
    "This method will take parameters window and consecutive as inputs and will return the training data sets, x_train and y_train.  The window parameter is an integer that is used to determine how many days to look back in order to predict the stock price for the next day.  The consecutive parameter is a boolean variable used to determine which method the training data will be generated.  The first way to generate the training data will be to use the window and then slide it along in time, incrementing by 1 day each iteration, but not changing the size of the window. Almost similar to convolution of an image. The second way to generate this training data will be to use the window and then have every iteration build on that window by one day.  Thus, the train data is gathered over consecutive days and forms a long term vision of the network.  The comments in the code will give a better description of each step and what that piece of code does for the entire method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cacf1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainData(data, window=90, consecutive=False):\n",
    "\n",
    "    #need to divide training data to account for the prediction days\n",
    "    #i.e. how many days to look back in order to predict the next day\n",
    "    #I plan to expirement with several windows - 15, 30, 45, 90 but \n",
    "    #starting out with 90\n",
    "    days = window\n",
    "    \n",
    "    #manipulating data so to add a correct label for the features\n",
    "    #by creating a 3D array\n",
    "\n",
    "    #itializing feature and label arrays\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    #iterating from the start of the window to the length of the data \n",
    "    #to get a window of days for data points and making the label that last\n",
    "    #day of that specific window\n",
    "    if not consecutive:\n",
    "        for i in range(days, len(train_data)):\n",
    "            x_train.append(train_data.iloc[i-days:i,[1,2,3,6]])\n",
    "            y_train.append(train_data.iloc[i,4])\n",
    "    \n",
    "    #looking back x days to start with to predict the next day but after the \n",
    "    #first iteration the number of days to look back in order to predict the next\n",
    "    #day grows by 1    \n",
    "    else: \n",
    "        for i in range(days, len(train_data)):\n",
    "            x_train.append(train_data.iloc[0:i,[1,2,3,6]])\n",
    "            y_train.append(train_data.iloc[i,4])   \n",
    "\n",
    "    #converting to numpy array     \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    #3D array in python - (layer, row, column)\n",
    "    #layer is each iteration of the loop, 1169\n",
    "    #row is number of days used to predict next day, 90\n",
    "    #column is the feature, Open, High, Low, or Volume \n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 4))\n",
    "    \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85abb91f",
   "metadata": {},
   "source": [
    "Test Data Method: This method will take parameters data and window and return the x_test and y_test data. This data will be used to test how accurate the model is in predicting the stock price of the next day.  The window parameter is  an integer that is used to determine how many days to look back in order to predict the stock price for the next day.  Data is the prepartitioned stock price data. Within the method, the data will be manipulated to the same format as the training data, i.e. a 3D dataframe with layers, rows, and columns sized accordingly. The layers represent the different iterations of the loop that will look back window days to predict the price of the next day.  The columns of dataframe are the features that will be fed into the model.  The number of rows will be the same length as the window.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68627efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTestData(data, window=90):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cbc6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPmodel(features, step_size, hidden_neurons=5, act='relu', loss_fxn='mean_squared_error'):\n",
    "    \n",
    "    #method inputs\n",
    "        #features - feature data used to get the number of input layer nodes\n",
    "        #step-size - for optimizer\n",
    "        #hidden_neurons - number of neurons in hidden layer, default of five\n",
    "        #act - activation function, default ReLu function\n",
    "        #loss_fxn - loss function, default as mean squared error\n",
    "    \n",
    "    #defining model\n",
    "    model = tf.keras.models.Sequential()\n",
    "   \n",
    "    #layers\n",
    "    model.add(tf.keras.layers.Dense(units=hidden_neurons,\n",
    "                                    input_shape=len(features.columns),\n",
    "                                    activation='relu')\n",
    "                                   )\n",
    "    model.add(tf.keras.layers.Dense(units = 1,\n",
    "                                    activation=act)\n",
    "                                   )\n",
    "    \n",
    "    #optimizer\n",
    "    opt = tf.keras.optimizers.Adam(learn_rate=step_size)\n",
    "    \n",
    "    #compile - loss fxn MSE\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=loss_fxn,\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "   \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bc9a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "def train_model(model, feature, label, epochs, batch_size):\n",
    "\n",
    "    #feeding features and labels to model, model iterates epoch number of times\n",
    "    #using batch_size number of data points per iteration\n",
    "    history = model.fit(x=feature,\n",
    "                        y=label,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs)\n",
    "\n",
    "    #weights and bias\n",
    "    trained_weight = model.get_weights()[0]\n",
    "    trained_bias = model.get_bias()[1]\n",
    "\n",
    "    #historical data of model for each epoch\n",
    "    epochs = history.epoch\n",
    "    hist = pd.DateFram(history.history)\n",
    "\n",
    "    #rmse for each epoch\n",
    "    rmse = hist[\"root_mean_squared_error\"]\n",
    "\n",
    "    return trained_weight, trained_bias, epochs, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "013ddb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict function\n",
    "def predict()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00daa6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
